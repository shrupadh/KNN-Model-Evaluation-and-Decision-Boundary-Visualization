---
title: "STMLMini_Project_A_1"
author: "Shradha Upadhyay"
date: "2024-09-02"
output:
  html_document: default
  word_document: default
  pdf_document: default
---

### (12 points) Consider the training and test data posted on eLearning in the files 1-tranining-data.csv
and 1-test-data.csv, respectively, for a classification problem with two classes.
# Loading Data
```{r, eval= FALSE}
#Loading training data
train_data <- read.csv("C:\\Users\\shrup\\OneDrive\\Desktop\\STML_Project\\1-training_data.csv")
#Loading test data
test_data <- read.csv("C:\\Users\\shrup\\OneDrive\\Desktop\\STML_Project\\1-test_data.csv")

# The k-nearest KNN algorith was applied for binary classification using the training and test datasets, with 'Y' as the response variable and 'x.1' and 'x.2' as the predictor variables. 

#Extracting  training data features and labels
train.x <- as.matrix(train_data[, -ncol(train_data)])
train.y <- as.factor(train_data[, ncol(train_data)])

#Extracting  test data features and labels

test.x <- as.matrix(test_data[, -ncol(test_data)])
test.y <- as.factor(test_data[, ncol(test_data)])

library(class)
```

##1.(a) Fit KNN with K = 1, 2, . . . , 100
```{r,eval= FALSE}
# Fit KNN for several values of K
# Define range of K values
ks <- c(seq(1, 100, by = 1))
nks <- length(ks)

#Initializing vectors to store error rates

err.rate.train <- numeric(length = nks)
err.rate.test <- numeric(length = nks)
#names(err.rate.train) <- names(err.rate.test) <- ks

for (i in seq(along = ks)) {
  set.seed(1)
  mod.train <- knn(train.x, train.x, train.y, k = ks[i])
  set.seed(1)
  mod.test <- knn(train.x, test.x, train.y, k = ks[i])

  #Calculating training and test error rates
  
 err.rate.train[i] <- 1 - sum(mod.train == train.y)/length(train.y)
 err.rate.test[i] <- 1 - sum(mod.test == test.y)/length(test.y)
}

```

##(b) Plot training and test error rates against K. Explain what you observe. Is it consistent with what you expect from the class?
```{r,eval= FALSE}
# Plot training and test error rate against K
plot(ks, err.rate.train, xlab = "Number of nearest neighbors(K)", ylab = "Error rate", 
     type = "b", ylim = range(c(err.rate.train, err.rate.test)), col = "blue", pch = 20, main= "Plot of training and test error rates against  K ")
# Add lines for the test error rate
lines(ks, err.rate.test, type="b", col="purple", pch = 20)

# Add a legend 
legend("bottomright", lty = 1, col = c("blue", "purple"), legend = c("training", "test"))

```



##(c) What is the optimal value of K? What are the training and test error rates associated with the optimal K?
```{r,eval= FALSE}
result <- data.frame(ks, err.rate.train, err.rate.test)
result[err.rate.test == min(result$err.rate.test),]
```

##(d) Draw a plot of the training data that also shows the decision boundary for the optimal K. Comment on what you observe. Does the decision boundary seem sensible?
```{r,eval= FALSE}
# Decision boundary for optimal K 
# Define the grid for plotting decision boundaries
n.grid <- 50 # Number of grid points

x1.grid <- seq(f = min(train.x[, 1]), t = max(train.x[, 1]), l = n.grid)
x2.grid <- seq(f = min(train.x[, 2]), t = max(train.x[, 2]), l = n.grid)
grid <- expand.grid(x1.grid, x2.grid)

# Set the optimal K value found in part(c)
k.opt <- 65
set.seed(1)

#Fit KNN model to the grid points to visualize the decision boundry
mod.opt <- knn(train.x, grid, train.y, k = k.opt, prob = T)

#Extract the probaility of the predicted class for the decision boundry
prob <- attr(mod.opt, "prob") # prob is voting fraction for winning class
prob <- ifelse(mod.opt == "yes", prob, 1 - prob) # now it is voting fraction for Direction == "Yes"
prob <- matrix(prob, n.grid, n.grid) # Reshape to match grid dimensions. 

#Plot the training data

plot(train.x, col = ifelse(train.y == "yes", "green", "red"),pch=20,xlab="Feature 1(x.1)", ylab="Feature 2 (x.2)", main= "Decision Boundry for Optimal K= 65")

# Add the decision boundary (contour at 0.5 level)
contour(x1.grid, x2.grid, prob, levels = 0.5, labels = "", xlab = "", ylab = "", 
        main = "", add = T,col="blue", lwd = 2)
#Add legend 
legend("bottomright", legend = c("Class 'Yes'", "Class 'No'", "Decision Boundary"), 
       col = c("green", "red", "blue"), pch = c(20, 20, NA),lty = c(NA, NA, 1),cex=0.5)

```